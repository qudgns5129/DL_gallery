{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from keras.layers import Input, Flatten, Dense, Conv2D, BatchNormalization, LeakyReLU, Dropout, Activation\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K \n",
    "\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASS = 10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# 이미지 데이터 정규화\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "y_train = to_categorical(y_train, NUM_CLASS)\n",
    "y_test = to_categorical(y_test, NUM_CLASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(64,64,1))\n",
    "\n",
    "conv_layer_1 = Conv2D(\n",
    "    filters = 2,\n",
    "    kernel_size = (3,3),\n",
    "    strides = 1,\n",
    "    padding = 'same')(input_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 shape가 (64,64,1)의 값을 가지고, conv층이 위와 같이 구성되어 있으면, 우선 필터개수가 2개이고 커널 사이즈가 (3,3)의 크기에 stride가 1 이고 패딩 사이즈가 same으로 설정되어 있으므로 출력 shape는 (배치 크기, 높이, 너비, 필터 개수) 이므로 (1, 64, 64, 2)의 크기로 반환이 될 것이다.\n",
    "  \n",
    "- 스트라이드 : 필터가 이동하는 크기\n",
    "- 패딩 : same 옵션을 주고 stride를 1로 설정하면, 입력과 출력의 크기를 같게 만들어 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cifar10 데이터에 적용하기\n",
    "input_layer = Input(shape=(32,32,3))\n",
    "\n",
    "conv_layer_1 = Conv2D(\n",
    "    filters = 10,\n",
    "    kernel_size = (4,4),\n",
    "    strides = 2,\n",
    "    padding = 'same')(input_layer)\n",
    "\n",
    "conv_layer_2 = Conv2D(\n",
    "    filters = 20,\n",
    "    kernel_size = (3,3),\n",
    "    strides = 2,\n",
    "    padding = 'same')(conv_layer_1)\n",
    "\n",
    "flatten_layer = Flatten()(conv_layer_2)\n",
    "\n",
    "output_layer = Dense(units = 10, activation='softmax')(flatten_layer)\n",
    "\n",
    "model = Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 10)        490       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 20)          1820      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                12810     \n",
      "=================================================================\n",
      "Total params: 15,120\n",
      "Trainable params: 15,120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- padding = 'same' 옵션인 합성곱 층의 출력 크기 : (None, 입력높이/스트라이드, 입력너비/스트라이드, 필터개수)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 합성곱, 배치정규화, 드롭아웃 적용한 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(32,32,3))\n",
    "\n",
    "x = Conv2D(filters = 32, kernel_size = 3, strides = 1, padding = 'same')(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters = 32, kernel_size = 3, strides = 2, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters = 64, kernel_size = 3, strides = 2, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(128)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(NUM_CLASS)(x)\n",
    "output_layer = Activation('softmax')(x)\n",
    "model = Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               524416    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 592,554\n",
      "Trainable params: 591,914\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.0005)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 632s 13ms/step - loss: 1.5692 - acc: 0.4498 - val_loss: 1.2337 - val_acc: 0.5667\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 641s 13ms/step - loss: 1.1750 - acc: 0.5844 - val_loss: 1.1258 - val_acc: 0.6007\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 634s 13ms/step - loss: 1.0129 - acc: 0.6462 - val_loss: 0.9474 - val_acc: 0.6715\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 592s 12ms/step - loss: 0.9243 - acc: 0.6783 - val_loss: 1.3200 - val_acc: 0.5658\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 625s 13ms/step - loss: 0.8626 - acc: 0.6978 - val_loss: 0.9578 - val_acc: 0.6652\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 577s 12ms/step - loss: 0.8098 - acc: 0.7174 - val_loss: 0.8387 - val_acc: 0.7045\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 544s 11ms/step - loss: 0.7588 - acc: 0.7343 - val_loss: 0.8840 - val_acc: 0.6980\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 542s 11ms/step - loss: 0.7279 - acc: 0.7458 - val_loss: 0.8198 - val_acc: 0.7163\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 542s 11ms/step - loss: 0.6851 - acc: 0.7609 - val_loss: 0.8473 - val_acc: 0.7131\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 582s 12ms/step - loss: 0.6564 - acc: 0.7719 - val_loss: 0.9108 - val_acc: 0.6916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a1cc99d2e8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train\n",
    "          , y_train\n",
    "          , batch_size=32\n",
    "          , epochs=10\n",
    "          , shuffle=True\n",
    "          , validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 26s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9108119547367096, 0.6916000127792359]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, batch_size=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_gallery",
   "language": "python",
   "name": "dl_gallery"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
